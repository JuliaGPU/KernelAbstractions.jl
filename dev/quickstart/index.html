<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Quickstart · KernelAbstractions.jl</title><link rel="canonical" href="https://juliagpu.github.io/KernelAbstractions.jl/quickstart/"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">KernelAbstractions.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Quickstart</a><ul class="internal"><li><a class="tocitem" href="#Terminology-1"><span>Terminology</span></a></li><li><a class="tocitem" href="#Writing-your-first-kernel-1"><span>Writing your first kernel</span></a></li><li><a class="tocitem" href="#Launching-kernel-on-the-host-1"><span>Launching kernel on the host</span></a></li><li><a class="tocitem" href="#Launching-kernel-on-the-device-1"><span>Launching kernel on the device</span></a></li><li><a class="tocitem" href="#Synchronization-1"><span>Synchronization</span></a></li></ul></li><li><a class="tocitem" href="../kernels/">Writing kernels</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../examples/memcopy/">Memcopy</a></li><li><a class="tocitem" href="../examples/memcopy_static/">Memcopy with static NDRange</a></li><li><a class="tocitem" href="../examples/naive_transpose/">Naive Transpose</a></li><li><a class="tocitem" href="../examples/performance/">Measuring performance</a></li><li><a class="tocitem" href="../examples/matmul/">Matmul</a></li></ul></li><li><a class="tocitem" href="../api/">API</a></li><li><span class="tocitem">Extras</span><ul><li><a class="tocitem" href="../extras/unrolling/">Unroll macro</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Quickstart</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Quickstart</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaGPU/KernelAbstractions.jl/blob/master/docs/src/quickstart.md#L" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Quickstart-1"><a class="docs-heading-anchor" href="#Quickstart-1">Quickstart</a><a class="docs-heading-anchor-permalink" href="#Quickstart-1" title="Permalink"></a></h1><h2 id="Terminology-1"><a class="docs-heading-anchor" href="#Terminology-1">Terminology</a><a class="docs-heading-anchor-permalink" href="#Terminology-1" title="Permalink"></a></h2><p>Because CUDA is the most popular GPU programming environment, we can use it as a reference for defining terminology in KA. A <em>workgroup</em> is called a block in NVIDIA CUDA and designates a group of threads acting in parallel, preferably in lockstep. For the GPU, the workgroup size is typically around 256, while for the CPU, it is usually a multiple of the natural vector-width. An <em>ndrange</em> is called a grid in NVIDIA CUDA and designates the total number of work items. If using a workgroup of size 1 (non-parallel execution), the ndrange is the number of items to iterate over in a loop.</p><h2 id="Writing-your-first-kernel-1"><a class="docs-heading-anchor" href="#Writing-your-first-kernel-1">Writing your first kernel</a><a class="docs-heading-anchor-permalink" href="#Writing-your-first-kernel-1" title="Permalink"></a></h2><p>Kernel functions are marked with the <a href="../api/#KernelAbstractions.@kernel"><code>@kernel</code></a>. Inside the <code>@kernel</code> macro you can use the <a href="../api/#api_kernel_language-1">kernel language</a>. As an example, the <code>mul2</code> kernel below will multiply each element of the array <code>A</code> by <code>2</code>. It uses the <a href="../api/#KernelAbstractions.@index"><code>@index</code></a> macro to obtain the global linear index of the current work item.</p><pre><code class="language-julia">@kernel function mul2_kernel(A)
  I = @index(Global)
  A[I] = 2 * A[I]
end</code></pre><h2 id="Launching-kernel-on-the-host-1"><a class="docs-heading-anchor" href="#Launching-kernel-on-the-host-1">Launching kernel on the host</a><a class="docs-heading-anchor-permalink" href="#Launching-kernel-on-the-host-1" title="Permalink"></a></h2><p>You can construct a kernel for a specific backend by calling the kernel with <code>mul2_kernel(CPU(), 16)</code>. The first argument is a device of type <code>KA.Device</code>, the second argument being the workgroup size. This returns a generated kernel executable that is then executed with the input argument <code>A</code> and the additional argument being a static <code>ndrange</code>.</p><pre><code class="language-julia">A = ones(1024, 1024)
ev = mul2_kernel(CPU(), 64)(A, ndrange=size(A))
wait(ev)
all(A .== 2.0)</code></pre><p>The kernel eventually returns an event <code>ev</code>. All kernels are launched asynchronously with the event <code>ev</code> specifies the current state of the execution. The [<code>wait</code>] blocks the <em>host</em> until the event <code>ev</code> has completed on the device. This implies that the host will launch no new kernels on any device until the wait returns.</p><h2 id="Launching-kernel-on-the-device-1"><a class="docs-heading-anchor" href="#Launching-kernel-on-the-device-1">Launching kernel on the device</a><a class="docs-heading-anchor-permalink" href="#Launching-kernel-on-the-device-1" title="Permalink"></a></h2><p>To launch the kernel on a backend-supported device <code>isa(device, KA.GPU)</code> (e.g., <code>CUDADevice()</code>, <code>ROCDevice()</code>, <code>oneDevice()</code>), we generate the kernel for this device provided by <code>CUDAKernels</code>, <code>ROCKernels</code>, or <code>oneAPIKernels</code>.</p><p>First, we initialize the array using the Array constructor of the chosen device with</p><pre><code class="language-julia">using CUDAKernels # Required to access CUDADevice
A = CuArray(ones(1024, 1024))</code></pre><pre><code class="language-julia">using ROCKernels # Required to access CUDADevice
A = ROCArray(ones(1024, 1024))</code></pre><pre><code class="language-julia">using oneAPIKernels # Required to access CUDADevice
A = oneArray(ones(1024, 1024))</code></pre><p>The kernel generation and execution are then</p><pre><code class="language-julia">ev = mul2_kernel(device, 64)(A, ndrange=size(A))
wait(ev)
all(A .== 2.0)</code></pre><p>For simplicity, we stick with the case of <code>device=CUDADevice()</code>.</p><h2 id="Synchronization-1"><a class="docs-heading-anchor" href="#Synchronization-1">Synchronization</a><a class="docs-heading-anchor-permalink" href="#Synchronization-1" title="Permalink"></a></h2><div class="admonition is-danger"><header class="admonition-header">Danger</header><div class="admonition-body"><p>All kernel launches are asynchronous, each kernel produces an event token that has to be waited upon, before reading or writing memory that was passed as an argument to the kernel. See <a href="../kernels/#dependencies-1">dependencies</a> for a full explanation.</p></div></div><p>The code around KA may heavily rely on <a href="https://github.com/JuliaGPU/GPUArrays.jl"><code>GPUArrays</code></a>, for example, to intialize variables.</p><pre><code class="language-julia">using CUDAKernels # Required to access CUDADevice
function mymul(A::CuArray)
    A .= 1.0
    ev = mul2_kernel(CUDADevice(), 64)(A, ndrange=size(A))
    wait(ev)
    all(A .== 2.0)
end</code></pre><p>These statement-level generated kernels like <code>A .= 1.0</code> are executed on a different stream than the KA kernels.  Launching <code>mul_kernel</code> may start before <code>A .= 1.0</code> has completed. To prevent this, we add a device-wide dependency to the kernel by adding <code>dependencies=Event(CUDADevice())</code>.</p><pre><code class="language-julia">ev = mul_kernel(CUDADevice(), 64)(A, ndrange=size(A), dependencies=Event(CUDADevice()))</code></pre><p>This device dependency requires all kernels on the device to be completed before this kernel is launched. In the same vein, multiple events may be added to a wait.</p><pre><code class="language-julia">using CUDAKernels # Required to access CUDADevice
function mymul(A::CuArray, B::CuArray)
    A .= 1.0
    B .= 3.0
    evA = mul2_kernel(CUDADevice(), 64)(A, ndrange=size(A), dependencies=Event(CUDADevice()))
    evB = mul2_kernel(CUDADevice(), 64)(A, ndrange=size(A), dependencies=Event(CUDADevice()))
    wait(evA, evB)
    all(A .+ B .== 8.0)
end</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../kernels/">Writing kernels »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Sunday 5 February 2023 19:33">Sunday 5 February 2023</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
